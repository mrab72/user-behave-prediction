{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_classifier_categories.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrab72/user-behave-prediction/blob/master/SVM_classifier_categories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "772Hlsv6Gyep"
      },
      "source": [
        "## Connect to the google drive:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWk48VPWrW_u"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyBZ-2eFsTqq"
      },
      "source": [
        "## Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ssYcybrqsr"
      },
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "import operator\n",
        "from django.utils.dateparse import parse_datetime\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn import svm\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQBFIsIrnlr7"
      },
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "clf.fit(feature_arr, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdRBLTd2scGE"
      },
      "source": [
        "## Load 84:241:9:79 Ip Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwDttiGisRuN"
      },
      "source": [
        "with open ('/content/drive/My Drive/tubp/file_84_241_9_79_apr.json', 'r') as f:\n",
        "  data = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq9MzQVux-24"
      },
      "source": [
        "with open ('/content/drive/My Drive/tubp/file_84_241_9_79_may.json', 'r') as f:\n",
        "  data_test = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOIseJyJtKn7"
      },
      "source": [
        "## Split Data into the n_minutes chunks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_vJAsWtCMP6"
      },
      "source": [
        "### parsed date from data:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhTfwhCru434"
      },
      "source": [
        "def _parsed_data(data):\n",
        "  parsed_data = {}\n",
        "  for date, traffic in data.items():\n",
        "    parsed_date = datetime.strptime(date.split('.')[0], '%Y-%m-%d-%H:%M:%S')\n",
        "    parsed_data[parsed_date] = traffic\n",
        "  return OrderedDict(sorted(parsed_data.items(), key=lambda t: t[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqJX0D0Av7qa"
      },
      "source": [
        "ordered_data = _parsed_data(data)\n",
        "ordered_data_test = _parsed_data(data_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpZMs54YFHXJ"
      },
      "source": [
        "def _internet_seq_chunk(ordered_data):\n",
        "  internet_seq_chunk = defaultdict(list)\n",
        "  for date, traffic_type in ordered_data.items():\n",
        "    new_date = (date - timedelta(0, 60 * (date.minute  % 60))).replace(second=0)\n",
        "    \n",
        "    internet_seq_chunk[new_date].append(traffic_type)\n",
        "  return internet_seq_chunk\n",
        "internet_seq_chunk = _internet_seq_chunk(ordered_data)\n",
        "internet_seq_chunk_test = _internet_seq_chunk(ordered_data_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yuBIIJ59Nwn"
      },
      "source": [
        "def create_type_seq(category, internet_seq_chunk):\n",
        "  cnt = 0\n",
        "  internet_seq = defaultdict()\n",
        "  for date, traffic_list in internet_seq_chunk.items():\n",
        "    cnt += len(traffic_list)\n",
        "    if category in traffic_list:\n",
        "      internet_seq[date] = 1\n",
        "    else:\n",
        "      internet_seq[date] = 0\n",
        "\n",
        "  internet_seq = OrderedDict(sorted(internet_seq.items(), key=lambda t: t[0]))\n",
        "  return internet_seq, cnt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ggZvE9Ni72Z"
      },
      "source": [
        "res, cnt = create_type_seq(\"Web\", internet_seq_chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU_g9TpYjG4G"
      },
      "source": [
        "distribution = {}\n",
        "for category in types:\n",
        "  res = create_type_seq(category, internet_seq_chunk)\n",
        "  distribution[category] = sum(list(res.values()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnTFnk8qjpNy"
      },
      "source": [
        "len(internet_seq_chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGswx-Esz_KT"
      },
      "source": [
        "total_seq = OrderedDict(([(datetime(2020, 1, 6, 12, 55), 0)]))\n",
        "date = datetime(2020, 1, 6, 12, 55)\n",
        "\n",
        "while date <= datetime(2020,4,14,7,10):\n",
        "  date = date + timedelta(0, 300)\n",
        "  total_seq[date] = sequence.get(date, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx1c7Br3pYP3"
      },
      "source": [
        "total_seq_test = OrderedDict(([(datetime(2020, 4, 14, 7, 10), 0)]))\n",
        "date = datetime(2020, 4, 14, 7, 10)\n",
        "\n",
        "while date <= datetime(2020, 4, 29, 6, 10):\n",
        "  date = date + timedelta(0, 300)\n",
        "  total_seq_test[date] = sequence_test.get(date, 0)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuJVsWk_2zNC"
      },
      "source": [
        "### Prepare dataset :\n",
        "\n",
        "\n",
        "*   one hot vector for day of week feature\n",
        "*   one hot vector for hour feature\n",
        "*   60 previous step as  feature\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwI0LTpq0qDK"
      },
      "source": [
        "def prepare_x_y(seq):\n",
        "  df = pd.DataFrame.from_dict(seq, orient='index').reset_index()\n",
        "  df = df.rename(columns={\"index\": \"time\", 0: \"usage\"})\n",
        "\n",
        "  day_of_weeks = pd.get_dummies(list(map( lambda x: x.dayofweek, list(df.time)))).values\n",
        "  hour = pd.get_dummies(list(map(lambda x: x.hour, list(df.time)))).values\n",
        "  minutes = pd.get_dummies(list(map(lambda x: x.minute, list(df.time)))).values\n",
        "\n",
        "  previous_steps = []\n",
        "  for i in range(len(df.usage.values)):\n",
        "    if i >= 20:\n",
        "      previous_steps.append(list(df.usage)[i - 20:i])\n",
        "    else:\n",
        "      previous_steps.append([0 for i in range(20)])\n",
        "\n",
        "  previous_steps_df = pd.DataFrame(previous_steps).values\n",
        "\n",
        "  return np.hstack((minutes, hour, day_of_weeks, previous_steps_df)), df.usage.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS_h0QyxoIeV"
      },
      "source": [
        "x_test, y_test  = prepare_x_y(total_seq_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK_L5rqiqFpn"
      },
      "source": [
        "y_predict = clf.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCRFBpgCqJvy"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvDwzBWgqbqz"
      },
      "source": [
        "precision_score(y_test, y_predict), recall_score(y_test, y_predict), accuracy_score(y_test, y_predict), f1_score(y_test, y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD8ewOQH9GT4"
      },
      "source": [
        "# Define a SVMClassifier class object "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhE5dpmErx7Q"
      },
      "source": [
        "class CategorySVMClassfier:\n",
        "\n",
        "  def __init__(self, category, train_file, test_file, n_minutes=5):\n",
        "    self.category = category \n",
        "    self.data = self._read_data_file(train_file)\n",
        "    self.data_test = self._read_data_file(test_file)\n",
        "    self.model = DecisionTreeClassifier(random_state=0) # svm.SVC()\n",
        "    self.n_minutes = n_minutes\n",
        "\n",
        "  def _read_data_file(self, directory):\n",
        "    with open(directory) as f:\n",
        "      return json.load(f)\n",
        "\n",
        "  def _parsed_data(self, data):\n",
        "    parsed_data = {}\n",
        "    for date, traffic in data.items():\n",
        "      parsed_date = datetime.strptime(date.split('.')[0], '%Y-%m-%d-%H:%M:%S')\n",
        "      parsed_data[parsed_date] = traffic\n",
        "    return OrderedDict(sorted(parsed_data.items(), key=lambda t: t[0]))\n",
        "\n",
        "  def _internet_seq_chunk(self, ordered_data):\n",
        "    internet_seq_chunk = defaultdict(list)\n",
        "    for date, traffic_type in ordered_data.items():\n",
        "      new_date = (date - timedelta(0, 60 * (date.minute  % self.n_minutes))).replace(second=0)\n",
        "      internet_seq_chunk[new_date].append(traffic_type)\n",
        "      \n",
        "    return internet_seq_chunk\n",
        "\n",
        "  def create_type_seq(self, category, internet_seq_chunk):\n",
        "    internet_seq = defaultdict()\n",
        "    for date, traffic_list in internet_seq_chunk.items():\n",
        "      if category in traffic_list:\n",
        "        internet_seq[date] = 1\n",
        "      else:\n",
        "        internet_seq[date] = 0\n",
        "\n",
        "    internet_seq = OrderedDict(sorted(internet_seq.items(), key=lambda t: t[0]))\n",
        "    return internet_seq\n",
        "\n",
        "  def _prepare_x_y(self, seq, usage):\n",
        "    df = pd.DataFrame.from_dict(seq, orient='index').reset_index()\n",
        "    df = df.rename(columns={\"index\": \"time\", 0: \"usage\"})\n",
        "\n",
        "    internt_usage_df = pd.DataFrame.from_dict(usage, orient='index').reset_index()\n",
        "    internt_usage_df = internt_usage_df.rename(columns={\"index\": \"time\", 0: \"usage\"})\n",
        "\n",
        "    day_of_weeks = pd.get_dummies(list(map( lambda x: x.dayofweek, list(df.time)))).values\n",
        "    hour = pd.get_dummies(list(map(lambda x: x.hour, list(df.time)))).values\n",
        "    minutes = pd.get_dummies(list(map(lambda x: x.minute, list(df.time)))).values\n",
        "\n",
        "    previous_steps = []\n",
        "    previous_usage = []\n",
        "    for i in range(len(df.usage.values)):\n",
        "      if i >= 100:\n",
        "        previous_steps.append(list(df.usage)[i - 100:i])\n",
        "        previous_usage.append(list(internt_usage_df.usage)[i - 100:i])\n",
        "        \n",
        "      else:\n",
        "        previous_steps.append([0 for i in range(100)])\n",
        "        previous_usage.append([0 for i in range(100)])\n",
        "\n",
        "    previous_steps_df = pd.DataFrame(previous_steps).values\n",
        "    previous_usage_df = pd.DataFrame(previous_usage).values\n",
        "\n",
        "    return np.hstack((minutes, hour, day_of_weeks, previous_steps_df)), df.usage.values\n",
        "\n",
        "  def _cover_all_times(self, seq):\n",
        "    total_seq = OrderedDict(([(min(list(seq.keys())), 0)]))\n",
        "    date = min(list(seq.keys()))\n",
        "    internet_usage = OrderedDict(([(min(list(seq.keys())), 0)]))\n",
        "    while date <= max(list(seq.keys())):\n",
        "      date = date + timedelta(0, 300)\n",
        "      total_seq[date] = seq.get(date, 0)\n",
        "      res = seq.get(date, None)\n",
        "      internet_usage[date]= 1 if res is not None else 0\n",
        "    return total_seq, internet_usage\n",
        "\n",
        "  def _prepare_data(self, data):\n",
        "    ordered_data = self._parsed_data(data)\n",
        "    internet_seq_chunk = self._internet_seq_chunk(ordered_data)\n",
        "    sequence = self.create_type_seq(self.category, internet_seq_chunk)\n",
        "    return self._cover_all_times(sequence)\n",
        "\n",
        "  def train(self):\n",
        "    total_seq, usage = self._prepare_data(self.data)\n",
        "    self.predict_len = len(total_seq)\n",
        "    print(\"start creating features array\")\n",
        "    x, y = self._prepare_x_y(total_seq, usage)\n",
        "    print(\"**************\")\n",
        "    print(\"start training model\")\n",
        "    self.model.fit(x, y)\n",
        "    print(\"*********************\")\n",
        "  \n",
        "  def evaluate(self):\n",
        "    total_seq, internet_usage = self._prepare_data(self.data_test)\n",
        "    x_test, y_test = self._prepare_x_y(total_seq, internet_usage)\n",
        "    y_predict = self.model.predict(x_test[self.predict_len:])\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision_score(y_test[self.predict_len:], y_predict),\n",
        "        \"recall\": recall_score(y_test[self.predict_len:], y_predict),\n",
        "        \"accuaracy\": accuracy_score(y_test[self.predict_len:], y_predict),\n",
        "        \"f1_score\": f1_score(y_test[self.predict_len:], y_predict)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWMtc1xd9joj"
      },
      "source": [
        "# train and evaluate model per category type:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o38ma-i5PyVI"
      },
      "source": [
        "types = [\n",
        "'Chat',\n",
        "'Cloud',\n",
        "'Database',\n",
        "'Email',\n",
        "'RemoteAccess',\n",
        "'SocialNetwork',\n",
        "'System',\n",
        "'Unspecified',\n",
        "'VoIP',\n",
        "'VPN',\n",
        "'Web'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2BnGeLgXayq"
      },
      "source": [
        "for category in types:\n",
        "  print(\"$$$$$$$$$$$%s$$$$$$$$$$$$\"%category)\n",
        "  for step in [5, 15, 30, 60]:\n",
        "    \n",
        "    train_file = '/content/drive/My Drive/tubp/file_84_241_9_79_apr.json'\n",
        "    test_file = '/content/drive/My Drive/tubp/file_84_241_9_79_may.json'\n",
        "    clf = CategorySVMClassfier(category, train_file, test_file, n_minutes=step)\n",
        "    clf.train()\n",
        "    print(\"***********%s***********\" % step)\n",
        "    print(\"+++++++++++++++result++++++++++++++\")\n",
        "    print(clf.evaluate())\n",
        "    \n",
        "  print(\"^^^^^^^^^^^^^^^^^^^END OF %s^^^^^^^^^^^^^^^^^^\" % category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdcmFni7w9m3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}